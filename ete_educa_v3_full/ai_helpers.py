import os
import json
import re
import sympy as sp
from dataclasses import dataclass
from dotenv import load_dotenv
from openai import OpenAI, OpenAIError
from typing import Dict, Any, Literal

# =====================================================
# ðŸ”¹ Carrega variÃ¡veis do arquivo .env automaticamente
# =====================================================
load_dotenv()

@dataclass
class AIConfig:
    api_key_env: str = "OPENAI_API_KEY"

# =====================================================
# ðŸ”¹ InicializaÃ§Ã£o segura do cliente
# =====================================================
def _client() -> OpenAI:
    """Cria e valida o cliente OpenAI."""
    cfg = AIConfig()
    api_key = os.getenv(cfg.api_key_env)

    if not api_key:
        raise RuntimeError(f"Defina {cfg.api_key_env} no arquivo .env.")

    if not api_key.startswith(("sk-", "sk-proj-")):
        raise RuntimeError("Chave OPENAI_API_KEY invÃ¡lida. Deve comeÃ§ar com 'sk-' ou 'sk-proj-'.")

    try:
        return OpenAI(api_key=api_key)
    except Exception as e:
        raise RuntimeError(f"Erro ao inicializar o cliente OpenAI: {e}")

# =====================================================
# ðŸ”¹ FunÃ§Ã£o central de chamada Ã  API (com suporte a gpt-5-mini)
# =====================================================
def _make_api_call(system_prompt: str, user_prompt: str, model: str, temperature: float = 1.0,
                   response_format: Dict[str, str] | None = None) -> str:
    """Executa chamadas Ã  API OpenAI com tratamento de erros."""
    try:
        client = _client()

        call_params = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        }

        # ðŸ”¹ SÃ³ adiciona temperature se o modelo suportar
        unsupported_temp_models = ["gpt-5-mini", "gpt-5"]
        if model not in unsupported_temp_models:
            call_params["temperature"] = temperature

        if response_format:
            call_params["response_format"] = response_format

        resp = client.chat.completions.create(**call_params)
        return resp.choices[0].message.content.strip()

    except OpenAIError as e:
        return f"âŒ Erro ao conectar Ã  OpenAI: {e.message}\nVerifique sua chave e conexÃ£o."
    except Exception as e:
        return f"âŒ Erro inesperado: {e}"

# =====================================================
# ðŸ”¹ GeraÃ§Ã£o de nova questÃ£o (A IA SÃ“ CRIA, NÃƒO RESOLVE)
# =====================================================
def generate_new_question(materia: str, topico: str) -> dict | None:
    """A IA gera a pergunta, as opÃ§Ãµes e a string da equaÃ§Ã£o."""
    
    system = (
        "VocÃª Ã© um assistente de IA especialista em criar questÃµes para o vestibular da ETE. "
        "Seu trabalho Ã© criar uma pergunta de mÃºltipla escolha (4 alternativas: a, b, c, d) sobre um tÃ³pico. "
        "VocÃª DEVE fornecer a equaÃ§Ã£o matemÃ¡tica pura, em formato SymPy, em um campo separado para que um "
        "computador possa resolvÃª-la e verificar."
        "\n\nREGRAS CRÃTICAS:\n"
        "1. PRECISÃƒO MATEMÃTICA Ã‰ PRIORIDADE MÃXIMA.\n"
        "2. NÃƒO inclua a chave 'correta' no JSON. O computador irÃ¡ calcular.\n"
        "3. A 'equacao_para_sympy' DEVE ser uma string que o SymPy possa resolver.\n"
        "4. A 'explicacao' deve ser um guia passo a passo, em tom AMIGÃVEL e ENCANTADOR, como se estivesse falando com um aluno de 14 anos. Use emojis (ðŸ’¡, ðŸ¤“, âœ…) para guiar."
    )
    
    user = f"""
Gere uma (1) nova questÃ£o de mÃºltipla escolha sobre o tÃ³pico abaixo.

MatÃ©ria: {materia}
TÃ³pico: {topico}

Responda apenas com JSON no formato:
{{
  "pergunta": "Seja y um nÃºmero real tal que 5^(y - 2) = 1/25. Qual Ã© o valor de y?",
  "opcoes": ["a) 0", "b) 1", "c) 2", "d) 3"],
  "equacao_para_sympy": "Eq(5**(y - 2), 1/25)",
  "variavel_solucao": "y",
  "explicacao": "ðŸ¤“ Ei, vamos lÃ¡! O truque aqui Ã© 'igualar as bases'..."
}}
"""

    json_string = _make_api_call(
        system_prompt=system,
        user_prompt=user,
        model="gpt-5-mini",
        temperature=1,
        response_format={"type": "json_object"}
    )

    if json_string.startswith("âŒ"):
        print(f"Erro ao gerar questÃ£o: {json_string}")
        return None

    try:
        return json.loads(json_string)
    except json.JSONDecodeError as e:
        print(f"Erro ao decodificar JSON: {e}")
        print(f"String recebida: {json_string}")
        return None

# =====================================================
# ðŸ”¹ FUNÃ‡ÃƒO DO "PROFESSOR CORRETOR" (PYTHON RESOLVE)
# =====================================================
def get_correct_answer_from_sympy(q_data: dict) -> tuple[str | None, str]:
    """
    Resolve a matemÃ¡tica usando SymPy para ENCONTRAR a resposta correta.
    Faz matching robusto: decimal com ponto/vÃ­rgula, fraÃ§Ã£o (a/b), nÃºmero misto (a b/c) e aproximaÃ§Ã£o.
    """
    import math
    try:
        equacao_str = q_data.get("equacao_para_sympy")
        variavel_str = q_data.get("variavel_solucao")
        opcoes = q_data.get("opcoes", [])

        if not equacao_str:
            return None, "Erro: A IA nÃ£o forneceu uma equaÃ§Ã£o para verificar."

        expr = sp.sympify(equacao_str)
        solucao_final = None

        # EquaÃ§Ã£o com variÃ¡vel (Eq(...))
        if isinstance(expr, sp.Equality) and variavel_str:
            variavel = sp.symbols(variavel_str)
            solucoes = sp.solve(expr, variavel)
            if solucoes:
                solucao_final = float(solucoes[0])

        # ExpressÃ£o direta (ex: 3**4 * 3**(-2))
        elif not variavel_str:
            solucao_final = float(expr.evalf())

        if solucao_final is None:
            return None, f"Erro: SymPy nÃ£o conseguiu resolver '{equacao_str}'."

        # TambÃ©m guardamos a forma fracionÃ¡ria exata, quando possÃ­vel (ex: 16/3)
        try:
            racional = sp.nsimplify(solucao_final)
        except Exception:
            racional = None

        # --- FunÃ§Ãµes auxiliares de parsing ---
        def extrair_valor(op_text: str) -> float | None:
            """
            Extrai um valor numÃ©rico da alternativa:
            - '16/3' -> 5.3333...
            - '5 1/3' (misto) -> 5.3333...
            - '5,33' ou '5.333' -> float
            Retorna None se nÃ£o conseguir.
            """
            txt = op_text.strip().lower()

            # remove rÃ³tulo 'a) ', 'b) ' etc.
            txt = re.sub(r"^[a-d]\)\s*", "", txt)

            # nÃºmero misto: "a b/c"
            m_misto = re.match(r"^\s*(\d+)\s+(\d+)\s*/\s*(\d+)\s*$", txt)
            if m_misto:
                a, b, c = map(int, m_misto.groups())
                if c != 0:
                    return a + (b / c)

            # fraÃ§Ã£o simples: "a/b"
            m_frac = re.match(r"^\s*(-?\d+)\s*/\s*(\d+)\s*$", txt)
            if m_frac:
                a, b = map(int, m_frac.groups())
                if b != 0:
                    return a / b

            # pega primeiro nÃºmero decimal na string (aceita vÃ­rgula)
            m_dec = re.search(r"-?\d+(?:[.,]\d+)?", txt)
            if m_dec:
                num = m_dec.group(0).replace(",", ".")
                try:
                    return float(num)
                except ValueError:
                    pass

            return None

        # --- Matching robusto ---
        for opcao in opcoes:
            # 1) comparaÃ§Ã£o por valor numÃ©rico com tolerÃ¢ncia (Â±0,01)
            val = extrair_valor(opcao)
            if val is not None:
                if math.isclose(val, solucao_final, rel_tol=0.0, abs_tol=0.01):
                    return opcao, "CÃ¡lculo verificado pelo Python (aproximaÃ§Ã£o numÃ©rica)."
                # tambÃ©m aceita igualdade pelas duas casas
                if round(val, 2) == round(solucao_final, 2):
                    return opcao, "CÃ¡lculo verificado pelo Python (duas casas decimais)."

            # 2) comparaÃ§Ã£o por fraÃ§Ã£o textual exata (ex: '16/3')
            if racional and isinstance(racional, sp.Rational):
                num = racional.p / racional.q
                frac_text = f"{int(racional.p)}/{int(racional.q)}"
                # remove rÃ³tulo e espaÃ§os
                opcao_limpa = re.sub(r"^[a-d]\)\s*", "", opcao.strip()).replace(" ", "")
                if opcao_limpa == frac_text:
                    return opcao, "CÃ¡lculo verificado pelo Python (fraÃ§Ã£o exata)."

        # Se chegou aqui, nÃ£o bateu nenhuma forma
        return None, (
            f"Erro: Nenhuma opÃ§Ã£o corresponde Ã  resposta correta ({solucao_final}). "
            "A IA pode ter criado opÃ§Ãµes invÃ¡lidas. Tente gerar outra."
        )

    except Exception as e:
        return None, f"Erro fatal no SymPy: {e}"


# =====================================================
# ðŸ”¹ FunÃ§Ãµes de texto (usam modelo mais barato)
# =====================================================
def explain_like_coach(question_text: str, materia: str) -> str:
    """Gera explicaÃ§Ãµes educativas e carinhosas (modo professora)."""
    system = (
        "VocÃª Ã© uma professora particular paciente e carinhosa para uma aluna de 14 anos "
        "que estÃ¡ estudando para o vestibular da ETE (Pernambuco). "
        "Explique de forma simples e com exemplos do dia a dia. "
        "Sempre divida a explicaÃ§Ã£o em 3 blocos:\n"
        "1ï¸âƒ£ O Pulo do Gato\n2ï¸âƒ£ Passo a Passo\n3ï¸âƒ£ Por que as outras estÃ£o erradas\n"
        "Finalize com uma dica divertida de memorizaÃ§Ã£o."
    )
    user = f"MatÃ©ria: {materia}\nQuestÃ£o:\n{question_text}\n\nExplique seguindo os 3 blocos e finalize com 1 dica curta de memorizaÃ§Ã£o."
    return _make_api_call(system_prompt=system, user_prompt=user, model="gpt-5-mini", temperature=1)

def ask_quick_question(pergunta: str) -> str:
    """Responde perguntas curtas de forma didÃ¡tica."""
    system = (
        "VocÃª Ã© um professor tira-dÃºvidas da ETE. "
        "Explique de forma simples, direta e com exemplos. "
        "Se for um conceito, dÃª uma frase explicando e um exemplo."
    )
    user = f"DÃºvida da aluna: {pergunta}"
    return _make_api_call(system_prompt=system, user_prompt=user, model="gpt-5-mini", temperature=1)
