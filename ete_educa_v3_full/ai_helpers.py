import os
import json
from dataclasses import dataclass
from dotenv import load_dotenv
from openai import OpenAI, OpenAIError
from typing import Dict, Any, Literal

# Carrega vari√°veis do arquivo .env automaticamente
load_dotenv()

@dataclass
class AIConfig:
    api_key_env: str = "OPENAI_API_KEY"
    # O modelo foi removido daqui, pois cada fun√ß√£o escolher√° o seu.

def _client() -> OpenAI:
    """Cria e valida o cliente OpenAI."""
    cfg = AIConfig()
    api_key = os.getenv(cfg.api_key_env)

    if not api_key:
        raise RuntimeError(f"Defina {cfg.api_key_env} no arquivo .env.")

    # Aceita tanto sk- quanto sk-proj-
    if not api_key.startswith(("sk-", "sk-proj-")):
        raise RuntimeError(
            "Chave OPENAI_API_KEY inv√°lida. Ela deve come√ßar com 'sk-' ou 'sk-proj-'."
        )

    try:
        return OpenAI(api_key=api_key)
    except Exception as e:
        raise RuntimeError(f"Erro ao inicializar o cliente OpenAI: {e}")

# =====================================================
# üîπ FUN√á√ÉO CENTRAL DE CHAMADA DE API (MELHORIA 1)
# =====================================================
def _make_api_call(
    system_prompt: str, 
    user_prompt: str, 
    model: str, 
    temperature: float,
    response_format: Dict[str, str] | None = None
) -> str:
    """
    Fun√ß√£o centralizada para fazer chamadas √† API OpenAI.
    Lida com a cria√ß√£o do cliente e o tratamento de erros.
    """
    try:
        client = _client()
        
        # Constr√≥i os par√¢metros da chamada
        call_params = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            "temperature": temperature,
        }
        
        # Adiciona o formato de resposta (JSON) se for solicitado
        if response_format:
            call_params["response_format"] = response_format

        resp = client.chat.completions.create(**call_params)
        return resp.choices[0].message.content.strip()

    except OpenAIError as e:
        # Lida com erros da API (chave errada, sem cr√©dito, etc.)
        return f"‚ùå Erro ao conectar √† OpenAI: {e.message}\nVerifique sua chave, cota e conex√£o."
    except Exception as e:
        # Lida com outros erros (ex: RuntimeError do _client)
        return f"‚ùå Erro inesperado: {e}"

# =====================================================
# üîπ Fun√ß√µes P√∫blicas (Agora mais limpas)
# =====================================================

def explain_like_coach(question_text: str, materia: str) -> str:
    """
    Gera explica√ß√µes educativas e carinhosas para aluna de 14 anos estudando para a ETE.
    """
    system = (
        "Voc√™ √© uma professora particular paciente e carinhosa para uma aluna de 14 anos "
        "se preparando para o vestibular da ETE (Pernambuco). "
        "Explique de forma simples, divertida e com exemplos reais do dia a dia. "
        "Sempre organize a resposta em tr√™s blocos: "
        "1Ô∏è‚É£ O Pulo do Gato, 2Ô∏è‚É£ Passo a Passo, 3Ô∏è‚É£ Por que as outras est√£o erradas. "
        "Finalize com uma dica de memoriza√ß√£o curta e divertida."
    )

    user = f"""
Mat√©ria: {materia}

Quest√£o (com alternativas, se houver):
{question_text}

Explique em 3 blocos:
1) O Pulo do Gato
2) Passo a Passo
3) Por que as outras est√£o erradas
Finalize com 1 dica de memoriza√ß√£o.
"""
    # Chama a fun√ß√£o central com o modelo r√°pido
    return _make_api_call(
        system_prompt=system,
        user_prompt=user,
        model="gpt-5-mini", # R√°pido e barato para explica√ß√µes
        temperature=0.5
    )


def generate_new_question(materia: str, topico: str) -> dict | None:
    """
    Gera uma nova quest√£o de m√∫ltipla escolha no estilo da ETE, 
    retornando um dicion√°rio (JSON).
    """
    
    # --- MELHORIA 2: PROMPT CORRIGIDO PARA MATEM√ÅTICA ---
    system = (
        "Voc√™ √© um assistente de IA especialista em criar quest√µes para o vestibular da ETE de Pernambuco (n√≠vel Ensino M√©dio). "
        "Voc√™ cria perguntas originais, no formato de m√∫ltipla escolha (4 alternativas: a, b, c, d), "
        "que seguem o estilo e o n√≠vel de dificuldade das provas passadas (como as da ETEP)."
        "\n\n"
        "REGRAS CR√çTICAS:"
        "1. PRECIS√ÉO MATEM√ÅTICA √â A PRIORIDADE M√ÅXIMA."
        "2. Pense passo a passo. Verifique todos os seus c√°lculos aritm√©ticos antes de gerar a resposta."
        "3. A explica√ß√£o deve ser 100% correta e justificar a resposta correta."
        "4. Exemplo de verifica√ß√£o: Se a express√£o for 81 - 8 + 5, o resultado √© 73 + 5 = 78. N√ÉO 70."
    )
    
    user = f"""
    Por favor, gere uma (1) nova quest√£o de m√∫ltipla escolha sobre o seguinte t√≥pico:
    
    Mat√©ria: {materia}
    T√≥pico do Edital: {topico}
    
    A quest√£o deve ser desafiadora, mas justa, similar √†s encontradas nas provas reais.
    
    Responda APENAS com um objeto JSON. O JSON deve ter a seguinte estrutura:
    {{
      "pergunta": "O enunciado completo da pergunta...",
      "opcoes": [
        "a) Texto da alternativa A",
        "b) Texto da alternativa B",
        "c) Texto da alternativa C",
        "d) Texto da alternativa D"
      ],
      "correta": "c) Texto da alternativa C",
      "explicacao": "Uma explica√ß√£o detalhada do porqu√™ esta √© a resposta certa e as outras est√£o erradas."
    }}
    """

    # --- MELHORIA 2: MODELO CORRIGIDO ---
    # 1. Chama a API com o modelo mais inteligente
    json_string = _make_api_call(
        system_prompt=system,
        user_prompt=user,
        model="gpt-4o", # Modelo potente para garantir a matem√°tica correta
        temperature=0.7,
        response_format={"type": "json_object"}
    )
    
    # 2. Verifica se a API retornou um erro
    if json_string.startswith("‚ùå"):
        print(f"Erro ao gerar quest√£o: {json_string}")
        return None

    # 3. Tenta fazer o parse do JSON (o erro agora √© s√≥ aqui)
    try:
        return json.loads(json_string)
    except json.JSONDecodeError as e:
        print(f"Erro ao decodificar JSON da IA: {e}")
        print(f"String recebida: {json_string}")
        return None


def ask_quick_question(pergunta: str) -> str:
    """
    Responde perguntas r√°pidas, como um dicion√°rio ou um professor tira-d√∫vidas.
    """
    system = (
        "Voc√™ √© um professor 'tira-d√∫vidas' para uma aluna de 14 anos. "
        "Sua especialidade √© a prova da ETE (Pernambuco). "
        "Responda de forma direta, simples e muito did√°tica. "
        "Se for uma defini√ß√£o de palavra, d√™ o significado e um exemplo de uso."
    )

    user = f"""
    D√∫vida da aluna:
    "{pergunta}"
    """
    
    # Chama a fun√ß√£o central com o modelo r√°pido
    return _make_api_call(
        system_prompt=system,
        user_prompt=user,
        model="gpt-5-mini", # R√°pido e barato para d√∫vidas
        temperature=0.3
    )